{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "mnist_valset, mnist_testset = torch.utils.data.random_split(mnist_testset, [int(0.9 * len(mnist_testset)), int(0.1 * len(mnist_testset))])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(mnist_valset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.models import ResNet50_Weights, resnet50\n",
    "\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Model, self).__init__()\n",
    "\n",
    "    self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    \n",
    "    num_ftrs = self.model.fc.in_features\n",
    "    self.model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /Users/jenda/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:17<00:00, 5.72MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0005, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "start_ts = time.time()\n",
    "\n",
    "losses = []\n",
    "batches = len(train_loader)\n",
    "val_batches = len(val_loader)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in progress:\n",
    "        X, y = data[0], data[1]\n",
    "        model.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss = loss.item()\n",
    "        total_loss += current_loss\n",
    "\n",
    "        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
    "        \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    val_losses = 0\n",
    "    precision, recall, f1, accuracy = [], [], [], []\n",
    "    \n",
    "    # set model to evaluating (testing)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            X, y = data[0], data[1]\n",
    "\n",
    "            outputs = model(X) # this get's the prediction from the network\n",
    "\n",
    "            val_losses += criterion(outputs, y)\n",
    "\n",
    "            predicted_classes = torch.max(outputs, 1)[1] # get class from network's prediction\n",
    "          \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
    "print(f\"Training time: {time.time()-start_ts}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "PATH = \"Model.pth\"\n",
    "save = False\n",
    "load = True\n",
    "\n",
    "if save:\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "if load:\n",
    "    model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 train images: 98.8 %\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_dataloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "#DRAWING\n",
    "import pygame as pg\n",
    "\n",
    "def init():\n",
    "    global screen\n",
    " \n",
    "    pg.init()\n",
    "    screen = pg.display.set_mode((500, 500))\n",
    "    mainloop()\n",
    " \n",
    " \n",
    "drawing = False\n",
    "last_pos = None\n",
    "w = 20\n",
    "color = (255, 255, 255)\n",
    " \n",
    " \n",
    "def draw(event):\n",
    "    global drawing, last_pos, w\n",
    " \n",
    "    if event.type == pg.MOUSEMOTION:\n",
    "        if (drawing):\n",
    "            mouse_position = pg.mouse.get_pos()\n",
    "            pg.draw.circle(screen, color, mouse_position, w)\n",
    "    elif event.type == pg.MOUSEBUTTONUP:\n",
    "        mouse_position = (0, 0)\n",
    "        drawing = False\n",
    "        last_pos = None\n",
    "    elif event.type == pg.MOUSEBUTTONDOWN:\n",
    "        drawing = True\n",
    "    elif event.type == pg.KEYDOWN:\n",
    "        drawing = True\n",
    "    elif event.type == pg.KEYUP:\n",
    "        drawing = False\n",
    " \n",
    " \n",
    "def mainloop():\n",
    "    global screen\n",
    " \n",
    "    run = True\n",
    "    while run:\n",
    "        for event in pg.event.get():\n",
    "            if event.type == pg.QUIT:\n",
    "                run = False\n",
    "            if event.type == pg.KEYDOWN:\n",
    "                if event.key == pg.K_SPACE:\n",
    "                    pg.image.save(screen, \"image.png\")\n",
    "                    run = False\n",
    "            draw(event)\n",
    "        pg.display.flip()\n",
    "    pg.quit()\n",
    "\n",
    " \n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CONVERTING\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, PILToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = Image.open(\"image.png\").convert(\"L\").resize((28,28),Image.Resampling.LANCZOS)\n",
    "\n",
    "transform = Compose([\n",
    "    PILToTensor(),\n",
    "    Lambda(lambda image: image.view(-1, 1, 28, 28))\n",
    "])\n",
    "\n",
    "# Y = (X-A)/(B-A) * (D-C) + C where x=input, ab=range in which is x, cd=range we want x to be\n",
    "func = lambda x: (x-0)/(255-0) * (1-0) + 0\n",
    "\n",
    "img_tensor = func(transform(image).to(torch.float))\n",
    "\n",
    "plt.imshow(img_tensor.view(28, 28).tolist(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jenda/Desktop/Coding/Python/MNIST/Main.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jenda/Desktop/Coding/Python/MNIST/Main.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#PREDICTING\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jenda/Desktop/Coding/Python/MNIST/Main.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jenda/Desktop/Coding/Python/MNIST/Main.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jenda/Desktop/Coding/Python/MNIST/Main.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jenda/Desktop/Coding/Python/MNIST/Main.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(img_tensor)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#PREDICTING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(img_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(predicted.tolist()[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "categories = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "accuracy = outputs.tolist()[0]\n",
    "ax.bar(categories,accuracy)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6d162b82f613d3628d1d1cae2a2921bdfc6fa4d7706309bf7cd6f0b0bdefa56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
